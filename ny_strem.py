import pandas as pd
import streamlit as st
import openai
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import nltk
import string

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report


from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
from nltk.stem.snowball import SnowballStemmer

from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt


#--------------------------------------------------------------------------------------------------------------------------#
print("Running...")
#V친r logga
st.image('logo2.jpg', width=300)  

#Den gr친a sidopanelen
st.markdown("Det ska vara l칛tt att hitta jobb f칬r just dig!")
st.markdown("---")

st.markdown('<br>', unsafe_allow_html=True)
st.markdown('<br>', unsafe_allow_html=True)


om_oss = (f'V친rt projekt arbete hamdlar om... Ett stort problem har uppt칛ckts.... Vill l칬sa detta... Genom intervjuer etc...')

vidare_lasning = """
Rapporten Swedish Elite Sport handlar om de svenska idrottarnas ekonomiska utmaningar, i j칛mf칬relse med v친ra grannar Norge och Danmark. 
Texten pekar p친 ett bristande svenskt idrottsst칬d under utvecklingsfasen som har resulterat i den nuvarande ekonomiska os칛kerheten 
hos v친ra svenska idrottare.
[L칛s mer](https://www.idan.dk/media/stgjthhj/swedish-elite-sport.pdf)

How 5 Athletes Afford to Stay in the Game and Still Make Rent 칛r en amerikansk artikel som handlar om hur idrottare, 
s칛rskilt kvinnor och i de mindre popul칛ra idrottsgrenarna, globalt sett lever i en ekonomisk kamp och os칛kerhet.
[L칛s mer](https://www.thecut.com/2024/01/pro-athletes-working-second-jobs-careers.html)"""

kontakt_uppgifter = """
Python Consulant 
Vera Hertzman
Vera@outlook.com
+46 76 848 23 49

Head of AI 
Thea H친kansson
Thea@gmail.se
+46 73 747 87 45

Head of Streamlit 
Frida Eriksson
Royal@yahoo.com
+46 76 432 38 49

Project Coordinator 
Miranda Tham
Miranda@hotmail.com
+46 76 767 00 35

Agenda and Report Administrator Tove Lennertsson
Tove@gmail.com
+46 0000000"""

bakgrund = """H칛r kommer info om projektets bakgrund """

left_column = st.sidebar.container()

#V칛nstra kolumnen
left_column.write("""
<style>
.left-column {
    background-color: #FF7F7F;
    width: 30%;
    padding: 20px;
    border-radius: 5px;
}
</style>
""", unsafe_allow_html=True)

                    #Texten i sidopanelen: annan text som vi kan l칛gga till
left_column.markdown("### Vi p친 <span style='color: #4a90e2;'>SPORTEE</span>", unsafe_allow_html=True)
                     #left_column.markdown("Info om v친rt projekt")

                    #Vidare l칛sning i sidopanelen

with left_column.expander("游눺 Om oss"):
    st.info(om_oss)

# Vidare l칛sning i sidopanelen
with left_column.expander("游닀   Vidare l칛sning"):
    st.info(vidare_lasning)

# Kontaktuppgifter i sidopanelen
with left_column.expander("游닒   Kontaktuppgifter"):
    st.info(kontakt_uppgifter)


# Bakgrund i sidopanelen
with left_column.expander("游늶   Projektets bakgrund"):
    st.info(bakgrund) 
#--------------------------------------------------------------------------------------------------------------------------#

#API nyckel 
API_KEY = open('Open_AI_key', 'r').read()

client = OpenAI(
    api_key=API_KEY
) 

# L칛s in API-nyckeln fr친n filen
with open("Open_AI_key", "r") as file:
    api_key = file.read().strip()

# Ange din API-nyckel
openai.api_key = api_key

#--------------------------------------------------------------------------------------------------------------------------#

@st.cache_data
def read_csv_file():
    # Read the CSV file into a DataFrame
    subset = pd.read_csv('subset.csv')
    return subset

# Load data using @st.cache
subset = read_csv_file()

print("Almost done!")

#--------------------------------------------------------------------------------------------------------------------------#
#CLUSTERING


#nltk.download('stopwords')
#nltk.download('punkt')

# Ladda in nltk:s stemmingfunktion f칬r svenska
stemmer_sv = SnowballStemmer("swedish")
# Ladda in stoppord f칬r svenska fr친n nltk
stop_words_sv = set(stopwords.words('swedish'))
# Ladda in engelska stoppord f칬r att hantera engelska texter
stop_words_en = set(stopwords.words('english'))
# Ladda in punktuation fr친n string
punctuation = set(string.punctuation)

# Select only relevant columns and make a copy to avoid SettingWithCopyWarning
new_subset = subset[[
    'headline',
    'description.text'
]].copy()

print("reading nltk")


#En funktion f칬r att f칬rbereada...
def preprocess_text(text, language='english'):
    # Convert list of keywords to a single string and then convert to lowercase
    if isinstance(text, list):
        text = ' '.join(text)
    # Convert text to lowercase
    text = text.lower()
    # Tokenize the text
    tokens = nltk.word_tokenize(text)
    # Remove stop words and punctuation based on language
    if language == 'swedish':
        stop_words = stop_words_sv
        stemmer = stemmer_sv
    else:
        stop_words = stop_words_en
        stemmer = SnowballStemmer("english")
    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]
    # Stem the tokens
    stemmed_tokens = [stemmer.stem(word) for word in tokens]
    # Join the stemmed tokens back into a single string
    text = ' '.join(stemmed_tokens)
    return text

# Apply text preprocessing with stemming
new_subset['combined_text'] = new_subset.apply(lambda row: preprocess_text((row['headline'] if pd.notnull(row['headline']) else '') + ' ' + (row['description.text'] if pd.notnull(row['description.text']) else ''), language='swedish'), axis=1)


# Justera vektoriseringen f칬r att anv칛nda olika parametrar
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(new_subset['combined_text'])

# Optimera antalet kluster med elbow method eller silhouette score

max_clusters = 10  # Justera detta beroende p친 dina data
silhouette_scores = []
for num_clusters in range(2, max_clusters + 1):
    kmeans = KMeans(n_clusters=num_clusters)
    kmeans.fit(X)
    silhouette_scores.append(silhouette_score(X, kmeans.labels_))

# Plotta silhouette score f칬r olika antal kluster
plt.plot(range(2, max_clusters + 1), silhouette_scores)
plt.xlabel('Antal kluster')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score f칬r olika antal kluster')
plt.show()

# Antal kluster, inklusive "Lagerarbete och logistik" och "칐vrigt"
optimal_num_clusters = 7  # Justera detta baserat p친 din analys

# Anv칛nd det optimala antalet kluster f칬r att utf칬ra klustringen
kmeans = KMeans(n_clusters=optimal_num_clusters)
kmeans.fit(X)


# Manuellt tilldela namn till varje kluster baserat p친 de framtr칛dande orden eller nyckelorden
cluster_names = [
    "Teknologi och IT",
    "H칛lsov친rd och medicin",
    "Utbildning och pedagogik",
    "Ekonomi och finans",
    "F칬rs칛ljning och marknadsf칬ring",
    "Lagerarbete och logistik",
    "칐vrigt"
]

# L칛gg till en ny kolumn i DataFrame f칬r branschnamn
subset['industry'] = [cluster_names[label] for label in kmeans.labels_]

#Fr친ga oss pratbubbla
st.markdown(
    """
    <div style="position: fixed; bottom: 20px; right: 20px; width: 90px; height: 40px; background-color: rgba(240, 240, 240, 0.8); border-radius: 10px; padding: 10px; display: flex; justify-content: center; align-items: center;">
        <div style="position: absolute; top: 50%; left: 100%; margin-top: -10px; width: 0; height: 0; border-top: 10px solid transparent; border-bottom: 10px solid transparent; border-left: 10px solid rgba(240, 240, 240, 0.8);"></div>
        <p style="margin: 0; color: #333;">Fr친ga oss!</p>
    </div> 
    """,
    unsafe_allow_html=True
)

print("clustering done!")

 
#--------------------------------------------------------------------------------------------------------------------------#

#Tabell d칛r man kan filtrera med b친da rullistorna
column_aliases = {
    'headline': 'headline',
    'employer.workplace': 'employer.workplace',
    'number_of_vacancies': 'number_of_vacancies',
    'description.text': 'description.text',
    'working_hours_type.label': 'working_hours_type.label',
    'workplace_address.region': 'workplace_address.region',
    'workplace_address.municipality': 'workplace_address.municipality',
    'duration.label': 'duration.label'
}

df = pd.read_csv("subset.csv")

places_list = subset['workplace_address.region'].dropna().unique().tolist()
places_list.insert(0, 'Visa alla')

time_of_work = subset['working_hours_type.label'].dropna().unique().tolist()
time_of_work.insert(0, 'Visa alla')

duration_time = subset['duration.label'].dropna().unique().tolist()
duration_time.insert(0, 'Visa alla')

# Visa titel 
st.subheader('Lediga jobb')

search_query = st.text_input('S칬k efter specifika ord:', value="", help="Jobbtitel, nyckelord eller f칬retag etc",)

region, form, time, branch = st.columns(4)


with region:
   selected_place = st.selectbox(f'V칛lj region:', places_list)

with form:
   selected_time_of_work = st.selectbox(f'V칛lj anst칛llningsform:', time_of_work)

with time:
   selected_duration_time = st.selectbox(f'V칛lj tidsomfattning', duration_time)

with branch:
    # Add a selectbox for industry sectors
    selected_industry = st.selectbox("V칛lj bransch:", ['Visa alla'] + cluster_names)


if selected_place == 'Visa alla':
    region_condition = subset['workplace_address.region'].notna()
else:
    region_condition = subset['workplace_address.region'] == selected_place

if selected_time_of_work == 'Visa alla':
    time_of_work_condition = subset['working_hours_type.label'].notna()
else:
    time_of_work_condition = subset['working_hours_type.label'] == selected_time_of_work

if selected_duration_time == 'Visa alla':
    duration_condition = subset['duration.label'].notna()
else:
    duration_condition = subset['duration.label'] == selected_duration_time

if search_query:
    text_condition = df['description.text'].str.contains(search_query, case=False, na=False)
else:
    text_condition = pd.Series(True, index=df.index)  # Default condition to select all rows

if selected_industry == 'Visa alla':
    industry_condition = subset['industry'].notna()
else:
    industry_condition = subset['industry'] == selected_industry

# Filtered subset based on all conditions
filtered_subset = subset[(region_condition) & (time_of_work_condition) & (duration_condition) & (text_condition) & (industry_condition)]
filtered_subset = filtered_subset.rename(columns=column_aliases) 

job_count = filtered_subset.shape[0]

#--------------------------------------------------------------------------------------------------------------------------#

#Visar hur m친nga lediga jobba som finns
st.markdown(f"<h1 style='font-weight: bold; color: #4a90e2'>{job_count} st </h1>", unsafe_allow_html=True)
st.markdown("Jobb som matchar s칬kningen:")


# V칛lj endast dessa tre kolumner
ny_subset = filtered_subset[[
    'headline',
    'employer.workplace',  
    'description.text'
]]

# Titel och text h칬gst upp
st.subheader('Lediga jobb')

print("starting with AI answers")

#antalet jobb
number = 2 
temp = st.empty()

#resultaten som visas
with temp.container():
    print("Laddar gpt")
    for i in range(min(len(ny_subset), number)):
        print(f'#{i}')
        with st.expander(f"Jobbannons {i+1} - {ny_subset['headline'].iloc[i]}"):
            st.write("-------------------------------------------------")
            # Anropa OpenAI f칬r att omformulera beskrivningstexten
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": """Du 칛r expert p친 att skriva snygga jobbannonser 
                     och alla jobbanonser ska vara skrivna p친 samma s칛tt det vill s칛ga med liknande rubriker och inneh친ll utan listor.
                     """},
                    {"role": "user", "content": filtered_subset['description.text'].iloc[i]},
                ]
            )

            #H칛mta och skriv ut den genererade omformulerade beskrivningen
            for choice in response.choices:
                simplified_description = choice.message.content
                st.write(f"{simplified_description}")


#visa fler alternativ
if len(ny_subset) > number:
    if st.button('Visa fler'):
        temp.empty()
        number += 2
        temp = st.empty()
        with temp.container():
            for i in range(number - 2, min(len(ny_subset), number)):
                with st.expander(f"Jobbannons {i+1} - {ny_subset['headline'].iloc[i]}"):
                    st.write("-------------------------------------------------")
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "Du 칛r expert p친 att skriva snygga jobbannonser"},
                            {"role": "user", "content": filtered_subset['description.text'].iloc[i]},
                        ]
                    )

                    #H칛mta och skriv ut den genererade omformulerade beskrivningen
                    for choice in response.choices:
                        simplified_description = choice.message.content
                        st.write(f"{simplified_description}")


#--------------------------------------------------------------------------------------------------------------------------#

#SUPERVISED LEARNING

# L칛s in data
df = pd.read_csv('subset.csv').head(206)
# L칛s in 'Headline' fr친n CSV-filen
pd.read_csv('subset.csv')['headline'].head(206)


# Skapa en kopia av den ursprungliga kolumnen
df['stemmed_text'] = df['description.text']

# Definiera stoppord
swedish_stop_words = set(stopwords.words('swedish'))
# Skapa en instans av SnowballStemmer f칬r svenska
stemmer = SnowballStemmer('swedish')

# Funktion f칬r textpreprocessering f칬r en specifik kolumn
def preprocess_text_column(column):
    # Tokenisera texten i kolumnen
    column_tokens = [word_tokenize(text.lower(), language='swedish') for text in column]
    # Ta bort stoppord och ord med en l칛ngd mindre 칛n 3, samt stamma ord
    preprocessed_column = []
    for tokens in column_tokens:
        filtered_tokens = [stemmer.stem(token) for token in tokens if token not in swedish_stop_words and len(token) > 2 and token.isalpha()]
        preprocessed_column.append(' '.join(filtered_tokens))  
    return preprocessed_column

# Preprocessa texten i kolumnen 'description.text'
df['stemmed_text'] = preprocess_text_column(df['stemmed_text'])

# Funktion f칬r att extrahera viktiga ord fr친n jobbannonser
def extract_manual_keywords():
    # Lista 칬ver manuellt valda viktiga ord
    manual_keywords = ["t칛vlingsinriktad", "35 timmar", "flexibelt arbete", "deltid", "extra personal"]
    
    return manual_keywords
# Extrahera de manuellt valda viktiga orden
manual_keywords = extract_manual_keywords()
# L칛gg till de manuellt valda viktiga orden i vokabul칛ren f칬r TF-IDF-vektoriseringen
vectorizer = TfidfVectorizer(vocabulary=manual_keywords)


# Manuellt m칛rkta etiketter f칬r de f칬rsta 200 raderna
labels = ["NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "JA", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA",
          "NEJ", "JA", "NEJ", "NEJ", "JA", "NEJ", "NEJ", "NEJ", "JA", "JA",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "NEJ", "NEJ", "NEJ", 
          "NEJ", "JA", "JA", "JA", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "JA", "NEJ", "JA", "NEJ", "JA", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ",
          "JA", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "JA", "JA", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "JA", "JA", "JA", "JA",
          "JA", "JA", "JA", "JA", "JA", "JA", "JA", "JA", "JA", "JA", "JA", "JA",
          "JA", "NEJ", "NEJ", "JA", "JA", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "NEJ",
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "NEJ", "JA", "NEJ", "JA", "NEJ", 
          "NEJ", "JA", "NEJ", "JA", "NEJ", "NEJ", "NEJ", "JA", "JA", "NEJ", "NEJ", 
          "NEJ", "NEJ", "NEJ", "NEJ", "JA", "NEJ", "JA", "JA", "NEJ", "NEJ", "NEJ", 
          "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "NEJ", "JA", "NEJ", "NEJ", "NEJ", 
          "NEJ", "NEJ", "JA", "JA", "NEJ", "JA", "JA", "NEJ"]

# Skapa en ny kolumn med namnet "label" och tilldela den dina manuellt m칛rkta etiketter
df['label'] = labels[:len(df)]
# Ta bara de f칬rsta 200 raderna som har en etikett
df_with_labels = df.dropna(subset=['label']).head(200)

# F칬rutsatt att ditt dataset finns i en DataFrame df med kolumnen "description.text" f칬r jobbannonserna och "label" f칬r etiketten
X = df_with_labels['stemmed_text']
y = df_with_labels['label']

# Dela upp data i tr칛ningsdata och testdata
# Dela upp data i tr칛ningsdata (150) och testdata (50) slumpm칛ssigt
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=120, test_size=80, random_state=42)
# Skapa TF-IDF-vektorer fr친n text med samma vokabul칛r som anv칛ndes f칬r tr칛ning
X_train_vectorized = vectorizer.fit_transform(X_train)
# Anv칛nd samma vektoriseringsinstans f칬r att transformera testdatan
X_test_vectorized = vectorizer.transform(X_test)

# V칛lj modell (Logistisk regression) och ange viktade klasser
model = LogisticRegression(max_iter=1000, class_weight={'NEJ': 1, 'JA': 10})

# Tr칛na modellen
model.fit(X_train_vectorized, y_train)
# F칬ruts칛g p친 testdata
y_pred = model.predict(X_test_vectorized)
# Utv칛rdera modellens prestanda
print(classification_report(y_test, y_pred))
# F칬ruts칛g l칛mpligheten f칬r varje jobbannons i ditt dataset
df['prediction'] = model.predict(vectorizer.transform(df['stemmed_text']))
# Sortera DataFrame baserat p친 f칬ruts칛gelserna f칬r att f친 jobbannonserna i kronologisk ordning f칬r vad som passar b칛st med idrott
sorted_df = df.sort_values(by='prediction', ascending=False)

st.markdown("---")
st.subheader("AI-generator", help="Detta 칛r endast en prototyp och inte en f칛rdigt utvecklad modell")
info = """Nedan listar en AI de tre b칛st l칛mpade arbeten f칬r elitidrottare. 
Dessa f칬rslag har utvecklats utifr친n en supervised model 
som tr칛nats f칬r att ge b칛sta m칬jliga rekommendation."""

st.write(info)
st.markdown('<br>', unsafe_allow_html=True)
st.markdown("<h6 style='text-align:left;'>Top tre:</h6>", unsafe_allow_html=True)


top_predictions = sorted_df[['headline','description.text', 'prediction']].head(3)


#Gpt genererade f칬rslag utifr친n filter
for i in range(len(top_predictions)):
        with st.expander(f"{top_predictions['headline'].iloc[i]}"):
            st.write("-------------------------------------------------")
            # Anropa OpenAI f칬r att omformulera beskrivningstexten
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": """Du 칛r expert p친 att skriva snygga jobbannonser 
                     och alla jobbanonser ska vara skrivna p친 samma s칛tt det vill s칛ga med liknande rubriker och inneh친ll utan listor.
                     """},
                    {"role": "user", "content": top_predictions['description.text'].iloc[i]},
                ]
            )

            #H칛mta och skriv ut den genererade omformulerade beskrivningen
            for choice in response.choices:
                simplified_description = choice.message.content
                st.write(f"{simplified_description}")

#--------------------------------------------------------------------------------------------------------------------------#

#Panelen l칛ngst ner
st.markdown('<br>', unsafe_allow_html=True)
st.markdown('<br>', unsafe_allow_html=True)


#Tjock linje innan
st.markdown(
    """
    <style>
        .line {
            width: 100%;
            height: 2px;
            background-color: black; /* Navy f칛rg */
            margin-bottom: 20px;
        }
    </style>
    <div class="line"></div>
    """,
    unsafe_allow_html=True
)

#Info l칛ngst ner i kolumner
safety, ass, terms, sportee = st.columns(4)

with safety:
    st.markdown("<h6 style='text-align:left;'>S칛kerhet</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Kunds칛kerhet</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Hantering av kunduppgifter</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Falska mail</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Anm칛l ett fel</h6>", unsafe_allow_html=True)
    

with ass:
    st.markdown("<h6 style='text-align:left;'>F칬r f칬reingen</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>L칛gg till egen annons</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>츿ndra layout</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Visa alla jobb</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Inloggning f칬r f칬renigar</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Administrera f칬reningsannonser</h6>", unsafe_allow_html=True)


with terms:
    st.markdown("<h6 style='text-align:left;'>Villkor</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Anv칛ndarvillkor</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Personuppgiftshantering</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Cookies</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Cookiesinst칛llningar</h6>", unsafe_allow_html=True)


with sportee:
    st.markdown("<h6 style='text-align:left;'>SPORTEE</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Om SPORTEE</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Press</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Jobba p친 SPORTEE</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Kontakta oss</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Inspiration</h6>", unsafe_allow_html=True)
    st.markdown("<h6 style='text-align:left; font-weight: 500;'>Tips och guider</h6>", unsafe_allow_html=True)

